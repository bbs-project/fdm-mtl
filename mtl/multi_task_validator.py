# multi_task_validator.py

import torch

from ultralytics.models.yolo.detect import DetectionValidator
from ultralytics.utils.metrics import ClassifyMetrics, ConfusionMatrix
from ultralytics.utils import LOGGER, ops

class MultiTaskValidator(DetectionValidator):
    """
    MultiTaskValidatorëŠ” DetectionValidatorë¥¼ ìƒì†ë°›ì•„ ë‹¤ìŒê³¼ ê°™ì€ ê¸°ëŠ¥ì„ ì¶”ê°€í•©ë‹ˆë‹¤:
    1. ë¶„ë¥˜(Classification) ì„±ëŠ¥ ì§€í‘œ(Top-1, Top-5 Accuracy)ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
    2. íƒì§€(Detection)ì™€ ë¶„ë¥˜(Classification) ì„±ëŠ¥ì„ ëª¨ë‘ í¬í•¨í•˜ëŠ” ì¢…í•©ì ì¸ í†µê³„ ë° fitness ì ìˆ˜ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    3. ìµœì¢… ê²€ì¦ ê²°ê³¼ ì¶œë ¥ì— ë¶„ë¥˜ ì„±ëŠ¥ì„ í•¨ê»˜ í‘œì‹œí•©ë‹ˆë‹¤.
    """

    def __init__(self, dataloader=None, save_dir=None, args=None, _callbacks=None):
        super().__init__(dataloader, save_dir, args, _callbacks)
        # ë¶„ë¥˜ ì„±ëŠ¥ ì¸¡ì •ì„ ìœ„í•œ metrics ê°ì²´ ì´ˆê¸°í™”
        self.cls_metrics = ClassifyMetrics()
        self.cls_preds = []
        self.cls_targets = []
        # self.names_clsëŠ” self.dataê°€ ì„¤ì •ëœ í›„ì¸ init_metricsì—ì„œ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.

    def init_metrics(self, model):
        super().init_metrics(model)
        # self.dataëŠ” __call__ ë©”ì„œë“œì—ì„œ trainerë¡œë¶€í„° ì„¤ì •ë˜ë¯€ë¡œ, ì´ ì‹œì ì—ì„œëŠ” ì•ˆì „í•©ë‹ˆë‹¤.
        self.names_cls = self.data.get('names_cls', self.data['names'])
        # ë¶„ë¥˜ ì‘ì—…ì— ëŒ€í•œ Confusion Matrix ì´ˆê¸°í™”. `names` ì¸ìë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
        self.cls_confusion_matrix = ConfusionMatrix(names=self.names_cls, task='classify')

        # =====ğŸ‘‡ ì—¬ê¸°ë¥¼ ì¶”ê°€í•´ì•¼ í•©ë‹ˆë‹¤. =====
        # ë§¤ ê²€ì¦ ì‹¤í–‰ ì‹œ, ì´ì „ ê²°ê³¼ë¥¼ ì €ì¥í•˜ë˜ ë¦¬ìŠ¤íŠ¸ë¥¼ ì´ˆê¸°í™”í•˜ì—¬ ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ë¥¼ ë°©ì§€í•©ë‹ˆë‹¤.
        self.cls_preds = []
        self.cls_targets = []
        # =====ğŸ‘† ì—¬ê¸°ê¹Œì§€ ì¶”ê°€ =====

    def postprocess(self, preds):
        """
        ëª¨ë¸ì˜ ì¶œë ¥ì„ í›„ì²˜ë¦¬í•©ë‹ˆë‹¤.
        (det_output, cls_output) íŠœí”Œì„ ë°›ì•„ det_outputë§Œ NMSì— ì „ë‹¬í•˜ê³ ,
        cls_outputì€ ë‚˜ì¤‘ì— ì‚¬ìš©í•˜ê¸° ìœ„í•´ ì €ì¥í•©ë‹ˆë‹¤.
        """
        det_output, cls_output = preds
        self.batch_cls_preds = cls_output  # update_metricsì—ì„œ ì‚¬ìš©í•˜ê¸° ìœ„í•´ ì €ì¥
        
        # ë¶€ëª¨ í´ë˜ìŠ¤ì˜ postprocessëŠ” NMSë¥¼ ìˆ˜í–‰í•˜ì—¬ íƒì§€ ê²°ê³¼ë§Œ ë°˜í™˜
        # DetectionValidatorì˜ postprocessëŠ” í…ì„œ í•˜ë‚˜ë§Œ ë°›ìœ¼ë¯€ë¡œ det_outputë§Œ ì „ë‹¬
        return super().postprocess(det_output)

    def update_metrics(self, preds, batch):
        """íƒì§€ ë° ë¶„ë¥˜ ë©”íŠ¸ë¦­ì„ ëª¨ë‘ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤."""
        # 1. Detection Metrics ì—…ë°ì´íŠ¸ (ë¶€ëª¨ í´ë˜ìŠ¤ ë¡œì§ ì¬ì‚¬ìš©)
        super().update_metrics(preds, batch)

        # 2. Classification Metrics ì—…ë°ì´íŠ¸
        cls_labels = batch.get('custom_cls_label')
        if cls_labels is not None and hasattr(self, 'batch_cls_preds') and self.batch_cls_preds is not None:
            # ê²€ì¦ ëª¨ë“œì—ì„œ Classify í—¤ë“œëŠ” (í™•ë¥ , ë¡œì§“) íŠœí”Œì„ ë°˜í™˜í•©ë‹ˆë‹¤.
            if isinstance(self.batch_cls_preds, tuple):
                cls_probs = self.batch_cls_preds[0]
                cls_logits = self.batch_cls_preds[1]
            else:  # ì˜ˆì™¸ì ì¸ ê²½ìš° (ì˜ˆ: í•™ìŠµ ëª¨ë“œ)
                cls_probs = self.batch_cls_preds.softmax(1)
                cls_logits = self.batch_cls_preds

            n5 = min(len(self.names_cls), 5)
            self.cls_preds.append(cls_logits.argsort(1, descending=True)[:, :n5].cpu())
            self.cls_targets.append(cls_labels.cpu())
            
            # Confusion matrixëŠ” ë¡œì§“ìœ¼ë¡œ ê³„ì‚°
            for p, t in zip(cls_logits.argmax(1).cpu().numpy(), cls_labels.cpu().numpy()):
                self.cls_confusion_matrix.matrix[p, t] += 1

    def get_stats(self):
        """íƒì§€ ë° ë¶„ë¥˜ í†µê³„ë¥¼ ê²°í•©í•˜ì—¬ ë°˜í™˜í•©ë‹ˆë‹¤."""
        # 1. Detection í†µê³„ ê°€ì ¸ì˜¤ê¸°
        stats = super().get_stats()

        # 2. Classification í†µê³„ ê³„ì‚° ë° ì¶”ê°€
        if self.cls_preds and self.cls_targets:
            self.cls_metrics.process(targets=self.cls_targets, pred=self.cls_preds)
            stats['top1_acc'] = self.cls_metrics.top1
            stats['top5_acc'] = self.cls_metrics.top5
            
            # F1-Score ê³„ì‚° (from confusion matrix)
            matrix = self.cls_confusion_matrix.matrix
            tp = matrix.diagonal()
            fp = matrix.sum(1) - tp
            fn = matrix.sum(0) - tp
            
            precision = tp / (tp + fp + 1e-9)
            recall = tp / (tp + fn + 1e-9)
            f1 = 2 * (precision * recall) / (precision + recall + 1e-9)
            
            stats['f1_score'] = f1.mean() if f1 is not None else 0.0

        else:
            stats['top1_acc'] = 0.0
            stats['top5_acc'] = 0.0
            stats['f1_score'] = 0.0

        # 3. Fitness ì ìˆ˜ ì¬ê³„ì‚° (íƒì§€ ì„±ëŠ¥ 80% + ë¶„ë¥˜ ì •í™•ë„ 10% + F1 10%)
        det_fitness = stats.get('fitness', 0.0)
        cls_acc_fitness = stats.get('top1_acc', 0.0)
        cls_f1_fitness = stats.get('f1_score', 0.0)
        stats['fitness'] = det_fitness * 0.8 + cls_acc_fitness * 0.1 + cls_f1_fitness * 0.1
        
        # print_resultsê°€ ì°¸ì¡°í•  ìˆ˜ ìˆë„ë¡ ê³„ì‚°ëœ ìµœì¢… statsë¥¼ self.statsì— ì €ì¥í•©ë‹ˆë‹¤.
        self.stats = stats
        return stats

    def print_results(self):
        """íƒì§€ ë° ë¶„ë¥˜ ê²°ê³¼ë¥¼ ëª¨ë‘ ì¶œë ¥í•©ë‹ˆë‹¤."""
        super().print_results()  # íƒì§€ ê²°ê³¼ í…Œì´ë¸”ì„ ë¨¼ì € ì¶œë ¥

        # ë¶„ë¥˜ ê²°ê³¼ë¥¼ ìƒˆë¡œìš´ í…Œì´ë¸”ë¡œ ëª…í™•í•˜ê²Œ ì¶œë ¥
        if self.cls_preds and self.cls_targets:
            LOGGER.info('')  # ì‹œê°ì  êµ¬ë¶„ì„ ìœ„í•œ ë¹ˆ ì¤„ ì¶”ê°€
            
            # ë¶„ë¥˜ í…Œì´ë¸” í—¤ë” ìƒì„± ë° ì¶œë ¥
            header_format = '%22s' + '%11s' * 3
            LOGGER.info(header_format % ('Class', 'Top-1 Acc', 'Top-5 Acc', 'F1-Score'))
            
            # ì¼ê´€ì„±ì„ ìœ„í•´ ëª¨ë“  ê°’ì„ self.statsì—ì„œ ê°€ì ¸ì˜µë‹ˆë‹¤.
            top1_acc = self.stats.get('top1_acc', 0.0)
            top5_acc = self.stats.get('top5_acc', 0.0)
            f1_score = self.stats.get('f1_score', 0.0)
            values_format = '%22s' + '%11.3g' * 3
            LOGGER.info(values_format % ('all', top1_acc, top5_acc, f1_score))
            
            if self.args.plots:
                # ë¶„ë¥˜ í´ë˜ìŠ¤ ì´ë¦„ì´ ìˆëŠ”ì§€ í™•ì¸í•˜ê³  ì „ë‹¬
                cls_names = getattr(self, 'names_cls', {})
                self.cls_confusion_matrix.plot(save_dir=self.save_dir, names=cls_names, on_plot=self.on_plot)

    @property
    def metric_keys(self):
        """Return the metric keys used for plotting."""
        keys = super().metric_keys
        keys.extend(['metrics/top1_acc', 'metrics/top5_acc', 'metrics/f1_score'])
        return keys
